"""
LLM Task Planner
----------------
LLM-based task planning with strict JSON output.
LLM outputs plans, not actions.

Hard Rules:
- Invalid JSON → discard
- Unknown tool → reject
- LLM output is never executed directly
"""

from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum, auto
from typing import Any, Dict, List, Optional, Union
import json
import logging
import os
import re

from pydantic import BaseModel, Field, ValidationError


class PlanStatus(Enum):
    """Status of a task plan."""
    VALID = auto()
    INVALID_JSON = auto()
    UNKNOWN_TOOL = auto()
    VALIDATION_ERROR = auto()
    LLM_ERROR = auto()


@dataclass
class ToolCall:
    """A single tool call in a plan."""
    tool_name: str
    arguments: Dict[str, Any]
    reasoning: str = ""
    
    def to_dict(self) -> Dict:
        return {
            "tool": self.tool_name,
            "arguments": self.arguments,
            "reasoning": self.reasoning
        }


@dataclass
class TaskPlan:
    """
    A plan generated by the LLM.
    Contains a sequence of tool calls to execute.
    """
    status: PlanStatus
    tool_calls: List[ToolCall] = field(default_factory=list)
    response_text: Optional[str] = None  # Direct response if no tools needed
    error: Optional[str] = None
    raw_output: str = ""
    timestamp: datetime = field(default_factory=datetime.now)
    
    @property
    def is_valid(self) -> bool:
        return self.status == PlanStatus.VALID
    
    @property
    def requires_tools(self) -> bool:
        return len(self.tool_calls) > 0
    
    def __repr__(self) -> str:
        if self.is_valid:
            if self.requires_tools:
                tools = ", ".join(tc.tool_name for tc in self.tool_calls)
                return f"TaskPlan(valid, tools=[{tools}])"
            return f"TaskPlan(valid, response='{self.response_text[:50]}...')"
        return f"TaskPlan({self.status.name}, error={self.error})"


@dataclass
class PlannerConfig:
    """Configuration for the LLM planner."""
    provider: str = "gemini"  # gemini, local
    model: str = "gemini-2.0-flash"
    api_key: Optional[str] = None
    base_url: Optional[str] = None  # For local models
    max_tokens: int = 1024
    temperature: float = 0.0  # Deterministic output
    timeout_seconds: float = 30.0


# System prompt for the LLM
SYSTEM_PROMPT = """You are JARVIS, a voice-controlled automation assistant. Your role is to understand user requests and plan appropriate tool calls.

CRITICAL RULES:
1. Always respond with valid JSON only
2. Never include explanatory text outside the JSON
3. If you cannot help, set "response" field with a message
4. Only use tools that are provided in the tool list
5. Be precise with argument types (strings, numbers, booleans)

Response Format:
{
    "thinking": "Brief reasoning about what the user wants",
    "tool_calls": [
        {
            "tool": "tool_name",
            "arguments": {"arg1": "value1"},
            "reasoning": "Why this tool"
        }
    ],
    "response": "Optional direct response if no tools needed"
}

If user request requires tools, populate tool_calls array.
If user request is a question you can answer directly, populate response.
Never populate both tool_calls and response."""


class LLMPlanner:
    """
    LLM-based task planner.
    
    Input: User text + available tool schemas
    Output: JSON plan only
    
    The LLM never executes anything - it only produces plans
    that are validated and executed by the tool executor.
    """
    
    def __init__(
        self,
        config: Optional[PlannerConfig] = None,
        tool_schemas: Optional[List[Dict]] = None
    ):
        self.config = config or PlannerConfig()
        self._tool_schemas = tool_schemas or []
        self._known_tools: set = set()
        self._logger = logging.getLogger("jarvis.planner")
        self._client = None
        
        # Extract known tool names
        for schema in self._tool_schemas:
            if "function" in schema:
                self._known_tools.add(schema["function"]["name"])
    
    def set_tool_schemas(self, schemas: List[Dict]) -> None:
        """Update the available tool schemas."""
        self._tool_schemas = schemas
        self._known_tools = set()
        for schema in schemas:
            if "function" in schema:
                self._known_tools.add(schema["function"]["name"])
    
    def _get_client(self):
        """Get or create the Gemini client."""
        if self._client is None:
            try:
                import warnings
                # Suppress deprecation warning for google.generativeai
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    import google.generativeai as genai
                
                api_key = self.config.api_key or os.getenv("GEMINI_API_KEY")
                if not api_key:
                    raise ValueError("Gemini API key not configured")
                
                genai.configure(api_key=api_key)
                self._client = genai.GenerativeModel(self.config.model)
                
            except ImportError:
                raise ImportError("google-generativeai package required. Install with: pip install google-generativeai")
        
        return self._client
    
    def plan(self, user_text: str, context: Optional[str] = None) -> TaskPlan:
        """
        Generate a task plan from user input.
        
        Args:
            user_text: The user's request
            context: Optional conversation context
        
        Returns:
            TaskPlan with tool calls or direct response
        """
        self._logger.info(f"Planning for: '{user_text}'")
        
        # Build messages
        messages = [
            {"role": "system", "content": self._build_system_prompt()},
        ]
        
        if context:
            messages.append({"role": "assistant", "content": context})
        
        messages.append({"role": "user", "content": user_text})
        
        # Call LLM with fallback to mock on quota exhaustion
        try:
            raw_output = self._call_llm(messages)
            self._logger.debug(f"LLM output: {raw_output}")
            
        except Exception as e:
            error_str = str(e).lower()
            
            # Check for quota exhaustion, rate limit, or configuration errors
            # All of these should fallback to mock planner
            if any(keyword in error_str for keyword in [
                "quota", "rate_limit", "resource_exhausted", "429",
                "not configured", "api key", "authentication", "unauthorized"
            ]):
                self._logger.warning(f"LLM unavailable, falling back to mock planner: {e}")
                return self._fallback_to_mock(user_text)
            
            self._logger.error(f"LLM call failed: {e}")
            return TaskPlan(
                status=PlanStatus.LLM_ERROR,
                error=str(e),
                raw_output=""
            )
        
        # Parse and validate output
        return self._parse_output(raw_output)
    
    def _fallback_to_mock(self, user_text: str) -> TaskPlan:
        """Fallback to mock planner when real LLM is unavailable."""
        self._logger.info("Using mock planner fallback")
        
        # Use the mock's _call_llm directly
        user_msg = user_text.lower()
        
        # Time-related
        if any(w in user_msg for w in ["time", "clock", "hour"]):
            return self._parse_output(json.dumps({
                "thinking": "User wants to know the time",
                "tool_calls": [
                    {"tool": "get_current_time", "arguments": {}, "reasoning": "Get current time"}
                ]
            }))
        
        # Date-related
        if any(w in user_msg for w in ["date", "day", "today"]):
            return self._parse_output(json.dumps({
                "thinking": "User wants to know the date",
                "tool_calls": [
                    {"tool": "get_current_date", "arguments": {"format": "long"}, "reasoning": "Get current date"}
                ]
            }))
        
        # Search
        if any(w in user_msg for w in ["search", "look up", "find"]):
            query = user_msg.replace("search for", "").replace("look up", "").strip()
            return self._parse_output(json.dumps({
                "thinking": "User wants to search the web",
                "tool_calls": [
                    {"tool": "web_search", "arguments": {"query": query}, "reasoning": "Web search"}
                ]
            }))
        
        # Open app
        if "open" in user_msg:
            apps = ["safari", "chrome", "spotify", "finder", "terminal", "notes", "photos"]
            for app in apps:
                if app in user_msg:
                    return self._parse_output(json.dumps({
                        "thinking": f"User wants to open {app}",
                        "tool_calls": [
                            {"tool": "open_application", "arguments": {"app_name": app.title()}, "reasoning": f"Open {app}"}
                        ]
                    }))
        
        # Volume
        if "volume" in user_msg:
            level = 50
            if "up" in user_msg or "louder" in user_msg:
                level = 75
            elif "down" in user_msg or "quiet" in user_msg:
                level = 25
            elif "mute" in user_msg:
                level = 0
            
            return self._parse_output(json.dumps({
                "thinking": "User wants to adjust volume",
                "tool_calls": [
                    {"tool": "set_volume", "arguments": {"level": level}, "reasoning": "Set volume"}
                ]
            }))
        
        # List files (but not scheduled tasks)
        if any(w in user_msg for w in ["files", "directory", "folder"]) or ("list" in user_msg and "schedule" not in user_msg):
            return self._parse_output(json.dumps({
                "thinking": "User wants to see files",
                "tool_calls": [
                    {"tool": "list_directory", "arguments": {"path": "."}, "reasoning": "List current directory"}
                ]
            }))
        
        # Screenshot
        if "screenshot" in user_msg or "screen shot" in user_msg:
            return self._parse_output(json.dumps({
                "thinking": "User wants a screenshot",
                "tool_calls": [
                    {"tool": "take_screenshot", "arguments": {"region": "full"}, "reasoning": "Capture screen"}
                ]
            }))
        
        # Camera
        if any(w in user_msg for w in ["camera", "photo", "picture", "webcam", "take a pic"]):
            return self._parse_output(json.dumps({
                "thinking": "User wants to capture from camera",
                "tool_calls": [
                    {"tool": "capture_camera", "arguments": {"analyze": False}, "reasoning": "Capture camera frame"}
                ]
            }))
        
        # List scheduled tasks
        if any(w in user_msg for w in ["list scheduled", "show scheduled", "list task", "scheduled tasks"]):
            return self._parse_output(json.dumps({
                "thinking": "User wants to see scheduled tasks",
                "tool_calls": [
                    {"tool": "list_scheduled_tasks", "arguments": {}, "reasoning": "List tasks"}
                ]
            }))
        
        # Schedule task
        if any(w in user_msg for w in ["schedule", "remind", "reminder", "alarm"]):
            # Try to extract time
            import re
            hour_match = re.search(r'(\d{1,2})\s*(am|pm|:)', user_msg)
            hour = 9  # Default to 9am
            if hour_match:
                h = int(hour_match.group(1))
                if 'pm' in user_msg and h < 12:
                    h += 12
                hour = h
            
            return self._parse_output(json.dumps({
                "thinking": "User wants to schedule a task",
                "tool_calls": [
                    {"tool": "schedule_task", "arguments": {
                        "name": "Scheduled reminder",
                        "action": "remind me",
                        "hour": hour,
                        "minute": 0
                    }, "reasoning": "Schedule task"}
                ]
            }))
        
        # Default: direct response
        return self._parse_output(json.dumps({
            "thinking": "No specific tool needed",
            "response": "[Mock fallback] I'm not sure how to help with that. Try asking about time, date, searching, opening apps, taking a screenshot, or scheduling tasks."
        }))
    
    def _build_system_prompt(self) -> str:
        """Build the system prompt with tool descriptions."""
        prompt = SYSTEM_PROMPT
        
        if self._tool_schemas:
            prompt += "\n\nAvailable Tools:\n"
            for schema in self._tool_schemas:
                func = schema.get("function", {})
                name = func.get("name", "unknown")
                desc = func.get("description", "")
                params = func.get("parameters", {})
                
                prompt += f"\n- {name}: {desc}\n"
                
                props = params.get("properties", {})
                if props:
                    prompt += "  Parameters:\n"
                    for param_name, param_info in props.items():
                        param_type = param_info.get("type", "any")
                        param_desc = param_info.get("description", "")
                        required = param_name in params.get("required", [])
                        req_str = " (required)" if required else ""
                        prompt += f"    - {param_name} ({param_type}){req_str}: {param_desc}\n"
        
        return prompt
    
    def _call_llm(self, messages: List[Dict]) -> str:
        """Call the LLM and return raw output."""
        client = self._get_client()
        
        # Convert messages to Gemini format
        # System message becomes part of the model's system instruction
        system_content = ""
        conversation = []
        
        for msg in messages:
            role = msg["role"]
            content = msg["content"]
            
            if role == "system":
                system_content = content
            elif role == "user":
                conversation.append({"role": "user", "parts": [content]})
            elif role == "assistant":
                conversation.append({"role": "model", "parts": [content]})
        
        # Create generation config
        generation_config = {
            "max_output_tokens": self.config.max_tokens,
            "temperature": self.config.temperature,
        }
        
        # Start chat with system instruction
        chat = client.start_chat(history=conversation[:-1] if len(conversation) > 1 else [])
        
        # Build the prompt with system context if this is the first message
        if system_content and conversation:
            prompt = f"{system_content}\n\n{conversation[-1]['parts'][0]}"
        elif conversation:
            prompt = conversation[-1]["parts"][0]
        else:
            prompt = ""
        
        response = chat.send_message(
            prompt,
            generation_config=generation_config
        )
        
        return response.text or ""
    
    def _parse_output(self, raw_output: str) -> TaskPlan:
        """Parse and validate LLM output."""
        # Try to extract JSON from output
        json_str = self._extract_json(raw_output)
        
        if not json_str:
            self._logger.warning("No valid JSON found in LLM output")
            return TaskPlan(
                status=PlanStatus.INVALID_JSON,
                error="No valid JSON in response",
                raw_output=raw_output
            )
        
        # Parse JSON
        try:
            data = json.loads(json_str)
        except json.JSONDecodeError as e:
            self._logger.warning(f"JSON parse error: {e}")
            return TaskPlan(
                status=PlanStatus.INVALID_JSON,
                error=f"JSON parse error: {e}",
                raw_output=raw_output
            )
        
        # Validate structure
        tool_calls = []
        
        if "tool_calls" in data and data["tool_calls"]:
            for tc in data["tool_calls"]:
                tool_name = tc.get("tool", "")
                
                # Check if tool exists
                if tool_name not in self._known_tools:
                    self._logger.warning(f"Unknown tool in plan: {tool_name}")
                    return TaskPlan(
                        status=PlanStatus.UNKNOWN_TOOL,
                        error=f"Unknown tool: {tool_name}",
                        raw_output=raw_output
                    )
                
                tool_calls.append(ToolCall(
                    tool_name=tool_name,
                    arguments=tc.get("arguments", {}),
                    reasoning=tc.get("reasoning", "")
                ))
        
        response_text = data.get("response")
        
        # Must have either tool_calls or response
        if not tool_calls and not response_text:
            return TaskPlan(
                status=PlanStatus.VALIDATION_ERROR,
                error="Plan must have tool_calls or response",
                raw_output=raw_output
            )
        
        return TaskPlan(
            status=PlanStatus.VALID,
            tool_calls=tool_calls,
            response_text=response_text,
            raw_output=raw_output
        )
    
    def _extract_json(self, text: str) -> Optional[str]:
        """Extract JSON from text, handling markdown code blocks."""
        text = text.strip()
        
        # Try to find JSON in code blocks
        code_block_pattern = r'```(?:json)?\s*\n?(.*?)\n?```'
        matches = re.findall(code_block_pattern, text, re.DOTALL)
        
        if matches:
            for match in matches:
                if self._is_valid_json(match.strip()):
                    return match.strip()
        
        # Try the whole text as JSON
        if self._is_valid_json(text):
            return text
        
        # Try to find JSON object in text
        brace_start = text.find('{')
        brace_end = text.rfind('}')
        
        if brace_start != -1 and brace_end != -1 and brace_end > brace_start:
            potential_json = text[brace_start:brace_end + 1]
            if self._is_valid_json(potential_json):
                return potential_json
        
        return None
    
    def _is_valid_json(self, text: str) -> bool:
        """Check if text is valid JSON."""
        try:
            json.loads(text)
            return True
        except:
            return False


class MockLLMPlanner(LLMPlanner):
    """
    Mock planner for testing without API calls.
    Uses pattern matching for deterministic responses.
    """
    
    def __init__(self, tool_schemas: Optional[List[Dict]] = None):
        super().__init__(
            config=PlannerConfig(provider="mock"),
            tool_schemas=tool_schemas
        )
    
    def _call_llm(self, messages: List[Dict]) -> str:
        """Generate mock response based on user input."""
        user_msg = messages[-1]["content"].lower()
        
        # Time-related
        if any(w in user_msg for w in ["time", "clock", "hour"]):
            return json.dumps({
                "thinking": "User wants to know the time",
                "tool_calls": [
                    {"tool": "get_current_time", "arguments": {}, "reasoning": "Get current time"}
                ]
            })
        
        # Date-related
        if any(w in user_msg for w in ["date", "day", "today"]):
            return json.dumps({
                "thinking": "User wants to know the date",
                "tool_calls": [
                    {"tool": "get_current_date", "arguments": {"format": "long"}, "reasoning": "Get current date"}
                ]
            })
        
        # Search
        if any(w in user_msg for w in ["search", "look up", "find"]):
            # Extract query
            query = user_msg.replace("search for", "").replace("look up", "").strip()
            return json.dumps({
                "thinking": "User wants to search the web",
                "tool_calls": [
                    {"tool": "web_search", "arguments": {"query": query}, "reasoning": "Web search"}
                ]
            })
        
        # Open app
        if "open" in user_msg:
            apps = ["safari", "chrome", "spotify", "finder", "terminal", "notes"]
            for app in apps:
                if app in user_msg:
                    return json.dumps({
                        "thinking": f"User wants to open {app}",
                        "tool_calls": [
                            {"tool": "open_application", "arguments": {"app_name": app.title()}, "reasoning": f"Open {app}"}
                        ]
                    })
        
        # Volume
        if "volume" in user_msg:
            level = 50  # Default
            if "up" in user_msg or "louder" in user_msg or "increase" in user_msg:
                level = 75
            elif "down" in user_msg or "quiet" in user_msg or "decrease" in user_msg:
                level = 25
            elif "mute" in user_msg:
                level = 0
            
            return json.dumps({
                "thinking": "User wants to adjust volume",
                "tool_calls": [
                    {"tool": "set_volume", "arguments": {"level": level}, "reasoning": "Set volume"}
                ]
            })
        
        # Screenshot
        if "screenshot" in user_msg or "screen shot" in user_msg:
            return json.dumps({
                "thinking": "User wants a screenshot",
                "tool_calls": [
                    {"tool": "take_screenshot", "arguments": {"region": "full"}, "reasoning": "Capture screen"}
                ]
            })
        
        # Camera
        if any(w in user_msg for w in ["camera", "photo", "picture", "webcam"]):
            return json.dumps({
                "thinking": "User wants to capture from camera",
                "tool_calls": [
                    {"tool": "capture_camera", "arguments": {"analyze": False}, "reasoning": "Capture camera"}
                ]
            })
        
        # List scheduled tasks
        if "scheduled" in user_msg and ("list" in user_msg or "show" in user_msg):
            return json.dumps({
                "thinking": "User wants to see scheduled tasks",
                "tool_calls": [
                    {"tool": "list_scheduled_tasks", "arguments": {}, "reasoning": "List scheduled tasks"}
                ]
            })
        
        # Schedule/Reminder
        if any(w in user_msg for w in ["schedule", "remind", "reminder", "alarm"]):
            return json.dumps({
                "thinking": "User wants to schedule a task",
                "tool_calls": [
                    {"tool": "schedule_task", "arguments": {
                        "name": "Reminder",
                        "action": "reminder alert",
                        "hour": 9,
                        "minute": 0
                    }, "reasoning": "Schedule task"}
                ]
            })
        
        # List files (but not scheduled)
        if any(w in user_msg for w in ["files", "directory", "folder"]) or ("list" in user_msg and "schedule" not in user_msg):
            return json.dumps({
                "thinking": "User wants to see files",
                "tool_calls": [
                    {"tool": "list_directory", "arguments": {"path": "."}, "reasoning": "List current directory"}
                ]
            })
        
        # Default: direct response
        return json.dumps({
            "thinking": "No specific tool needed",
            "response": "I'm not sure how to help with that. Try asking about time, date, searching, opening apps, screenshots, or scheduling."
        })


def test_planner() -> None:
    """Test the LLM planner with mock."""
    from tools.registry import create_default_tools
    
    print("Testing LLM Planner (Mock)...")
    
    # Create registry and get schemas
    registry = create_default_tools()
    schemas = registry.get_schemas_for_llm()
    
    # Create mock planner
    planner = MockLLMPlanner(tool_schemas=schemas)
    
    test_cases = [
        "What time is it?",
        "What's the date today?",
        "Search for Python tutorials",
        "Open Spotify",
        "Set volume to 50",
        "List files in the current directory",
        "Hello, how are you?",
    ]
    
    print("\nPlanning Tests:")
    print("-" * 60)
    
    for query in test_cases:
        plan = planner.plan(query)
        print(f"\n'{query}'")
        print(f"  → {plan}")
        if plan.is_valid and plan.requires_tools:
            for tc in plan.tool_calls:
                print(f"    Tool: {tc.tool_name}({tc.arguments})")
    
    print("\nAll tests passed!")


if __name__ == "__main__":
    test_planner()
